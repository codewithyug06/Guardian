import os
import re
import numpy as np
import random
import networkx as nx
from pathlib import Path
from dotenv import load_dotenv
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import CharacterTextSplitter
from langchain_core.documents import Document
from sklearn.ensemble import IsolationForest

# 1. Robust Environment Loading
env_path = Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

if not os.getenv("OPENAI_API_KEY"):
    load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")

# 2. Initialize Tools
try:
    if api_key:
        tool_llm = ChatOpenAI(api_key=api_key, model="gpt-4o", temperature=0)
    else:
        tool_llm = None
except:
    tool_llm = None

search_tool = DuckDuckGoSearchRun()

# --- PHASE 8: FEDERATED RISK TOOLS (NEW) ---

def fetch_federated_insights():
    """
    Simulates connecting to a Privacy-Preserving Federated Network.
    Retrieves 'Model Gradients' or 'Threat Signatures' from peer banks 
    without sharing any customer data.
    """
    # Simulated "Encrypted" Insights from the Network
    global_threats = [
        "üåê FED-NET: Peer Bank A detected 'Micro-Structuring' (<$100) at 50ms intervals.",
        "üåê FED-NET: Peer Bank B updated weights for 'Obfuscated SQL' patterns.",
        "üåê FED-NET: Global Consensus: Adjusting Isolation Forest contamination to 0.15."
    ]
    return random.choice(global_threats)

# --- PHASE 7: ADVERSARIAL TOOLS ---

def simulate_adversarial_attack():
    """Generates Red Team attack patterns."""
    attacks = [
        "üëª GHOST: Injecting 'Structuring' Pattern -> 50x transactions of $9,900 (Just below $10k threshold).",
        "üëª GHOST: Attempting Policy Bypass -> Injecting obfuscated SQL in transaction metadata.",
        "üëª GHOST: Velocity Flood -> Simulating 10,000 requests/sec DDoS signature."
    ]
    return random.choice(attacks)

# --- PHASE 6: KNOWLEDGE GRAPH ---

REGULATORY_GRAPH = None

def _init_regulatory_graph():
    G = nx.DiGraph()
    G.add_node("Concept: Encryption", type="Topic")
    G.add_node("Concept: Data Retention", type="Topic")
    G.add_node("PCI-DSS 3.4", type="Regulation", text="PAN must be unreadable anywhere it is stored.")
    G.add_node("GDPR Art 32", type="Regulation", text="Security of processing requires encryption.")
    G.add_node("Internal Policy Cl 2", type="Policy", text="Credit Card numbers may be stored in plain text.")
    G.add_node("Internal Policy Cl 1", type="Policy", text="User logs retained for 5 years.")
    G.add_edge("Concept: Encryption", "PCI-DSS 3.4", relation="Mandated By")
    G.add_edge("Concept: Encryption", "GDPR Art 32", relation="Mandated By")
    G.add_edge("Internal Policy Cl 2", "Concept: Encryption", relation="Relates To")
    G.add_edge("PCI-DSS 3.4", "GDPR Art 32", relation="Semantically Linked")
    return G

def query_regulatory_mesh(topic_keyword):
    global REGULATORY_GRAPH
    if REGULATORY_GRAPH is None: REGULATORY_GRAPH = _init_regulatory_graph()
    mesh_insights = []
    try:
        entry_node = None
        if "Credit Card" in topic_keyword or "PCI" in topic_keyword: entry_node = "Internal Policy Cl 2"
        elif "Retention" in topic_keyword: entry_node = "Internal Policy Cl 1"
        if entry_node and REGULATORY_GRAPH.has_node(entry_node):
            neighbors = list(REGULATORY_GRAPH.neighbors(entry_node))
            impacts = []
            for n in neighbors:
                secondary = list(REGULATORY_GRAPH.neighbors(n))
                for sec in secondary:
                    if REGULATORY_GRAPH.nodes[sec].get('type') == 'Regulation':
                        impacts.append(sec)
                        tertiary = list(REGULATORY_GRAPH.neighbors(sec))
                        for tert in tertiary:
                             if REGULATORY_GRAPH.nodes[tert].get('type') == 'Regulation':
                                 impacts.append(f"{tert} (via Mesh Link)")
            mesh_insights.append(f"üï∏Ô∏è GRAPH TRAVERSAL START: {entry_node}")
            mesh_insights.append(f"üîó CONNECTED CONCEPTS: {', '.join(neighbors)}")
            mesh_insights.append(f"üö® DOWNSTREAM IMPACTS: {', '.join(impacts)}")
        else:
            mesh_insights.append("üï∏Ô∏è Graph Scan: No direct semantic sub-graph found.")
    except Exception as e: return f"Graph Error: {str(e)}"
    return "\n".join(mesh_insights)

# --- PHASE 5: VERIFICATION TOOLS ---

def perform_chain_of_verification(regulatory_claim):
    verification_steps = []
    if "PCI" in regulatory_claim or "Card" in regulatory_claim:
        verification_steps.append("‚úÖ Source A (Official Text): Clause matches PCI-DSS v4.0.")
    elif "GDPR" in regulatory_claim:
        verification_steps.append("‚úÖ Source A (Official Text): Clause matches EU GDPR.")
    else:
        verification_steps.append("‚ÑπÔ∏è Source A (Official Text): Regulatory alignment checked.")
    verification_steps.append("‚úÖ Source B (Legal Precedents): No conflicting case law.")
    verification_steps.append("‚úÖ Source C (Enforcement): Topic is currently stable.")
    log = "\n".join(verification_steps)
    return f"\n[‚õìÔ∏è CHAIN-OF-VERIFICATION LOG]\n{log}\n[VERDICT]: VERIFIED (3/3 Sources)"

# --- PHASE 4: VISION TOOLS ---

def analyze_dashboard_image(image_bytes):
    try:
        if not tool_llm: raise Exception("No API Access")
        raise Exception("Simulating Vision API Call")
    except Exception:
        return "VISION ANALYSIS: Detected Error Code '0x889'. Correlates with 'Gateway Timeout'."

def verify_regulatory_citation(finding):
    known_regs = ["PCI-DSS", "GDPR", "CCPA", "NIST", "ISO"]
    if any(reg in finding for reg in known_regs): return "‚úÖ VERIFIED: Citation matches known frameworks."
    return "‚ö†Ô∏è CAUTION: Citation could not be cross-referenced."

# --- PHASE 3: ML TOOLS (UPDATED) ---

def detect_velocity_anomaly(simulation_mode="ATTACK", federated_active=False):
    """
    Real ML: Uses Isolation Forest.
    UPDATED: If 'federated_active' is True, the model adapts to global intelligence
    (simulated by training on a broader 'Normal' dataset representing peer banks).
    """
    try:
        rng = np.random.RandomState(42)
        
        # Base Normal Behavior (Local Data)
        X_train = rng.normal(loc=60, scale=10, size=100).reshape(-1, 1)
        
        # Federated Learning Adjustment:
        # If enabled, we "learn" from peer banks that tighter intervals are also normal in some contexts,
        # OR that specific bursts are definitely attacks.
        # For this demo, we increase sensitivity (contamination) based on 'Global Alerts'.
        contamination_level = 0.1
        if federated_active:
            # Simulate receiving a model update that creates a stricter boundary
            contamination_level = 0.2 
            
        clf = IsolationForest(random_state=42, contamination=contamination_level)
        clf.fit(X_train)
        
        if simulation_mode == "ATTACK":
            current_data = np.array([[0.1]]) 
        else:
            current_data = np.array([[55.0]])
            
        prediction = clf.predict(current_data)
        return prediction[0] == -1
    except Exception as e:
        print(f"ML Tool Error: {e}")
        return True 

def generate_risk_forecast(current_risk_level):
    days = 30
    forecast = []
    if current_risk_level in ["HIGH", "CRITICAL"]:
        base = 80; trend = 0.5
    else:
        base = 20; trend = -0.2
    for i in range(days):
        noise = random.randint(-5, 5)
        val = base + (trend * i) + noise
        forecast.append(max(0, min(100, int(val))))
    return forecast

# --- PHASE 2: RAG TOOLS ---

RAG_RETRIEVER = None

def _get_rag_context(query: str):
    global RAG_RETRIEVER
    try:
        if not api_key: return None
        if RAG_RETRIEVER is None:
            policy_path = Path(__file__).parent.parent / "internal_policy.txt"
            if not policy_path.exists(): return None
            with open(policy_path, "r") as f: text = f.read()
            text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
            texts = text_splitter.split_text(text)
            docs = [Document(page_content=t) for t in texts]
            embeddings = OpenAIEmbeddings()
            db = Chroma.from_documents(docs, embeddings)
            RAG_RETRIEVER = db.as_retriever(search_kwargs={"k": 2})
        docs = RAG_RETRIEVER.get_relevant_documents(query)
        return "\n".join([d.page_content for d in docs])
    except Exception as e:
        print(f"RAG Warning: {e}")
        return None

def pci_pii_sentry_scan(log_text: str):
    patterns = {
        "PCI_CARD": r"\b(?:\d[ -]*?){13,16}\b",
        "GDPR_EMAIL": r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b",
        "SSN_PII": r"\b\d{3}-\d{2}-\d{4}\b"
    }
    violations = [label for label, pat in patterns.items() if re.search(pat, log_text)]
    return violations if violations else ["CLEAN"]

def calculate_potential_fine(violation_type: str):
    try:
        if not tool_llm: raise Exception("No LLM")
        prompt = f"Estimate fine for '{violation_type}'. Return ONLY amount."
        return tool_llm.invoke(prompt).content
    except:
        if "PCI" in violation_type: return "$100,000/mo (PCI Fee)"
        return "‚Ç¨20 Million (GDPR Max)"

def regulatory_gap_analyzer(new_regulation: str):
    policy_context = _get_rag_context(new_regulation)
    method_used = "Hybrid: Vector Search + Knowledge Graph"
    graph_context = query_regulatory_mesh(new_regulation)
    
    if not policy_context:
        try:
            with open(Path(__file__).parent.parent / "internal_policy.txt", "r") as f:
                policy_context = f.read()
            method_used = "Full-Document Scan (Fallback)"
        except: return "Error reading policy."

    prompt = f"""
    You are a Senior Compliance Auditor. 
    Compare Reg: '{new_regulation}' vs Policy: '{policy_context}'.
    Graph Context: {graph_context}
    Return ONLY the violation analysis in one clear sentence.
    """
    try:
        if not tool_llm: raise Exception("No LLM")
        return tool_llm.invoke(prompt).content
    except:
        return "VIOLATION DETECTED: Clause 2 (Plain-text PAN) violates PCI-DSS 3.4."